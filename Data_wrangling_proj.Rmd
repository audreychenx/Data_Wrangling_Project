---
title: "Ideal States for MSDS Students"
author: "Xuejun Chen"
date: "2018/4/30"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

<!-- install reguired packages, API KEY can be found on Sakai --> 

```{r setup, include=FALSE}
## Packages Required
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(rvest)
library(tidyverse)
library(stringr)
library(choroplethr)
library(DT) 
library(dplyr)
library(ggplot2)
library(ggmap)    
library(maps)    
library(mapdata)  
library(leaflet)
devtools::install_github("dkahle/ggmap")

## API KEY
register_google(key ="AIzaSyCW-LU6v7mdJVWp8tfpYHYQ2rkVSSGf_mY")
```




<!-- 

1.Scrap data from Indeed.com for 5 job titles and tidy them
2.Combine 5 table in one
3.Create a table to 

--> 

## Tidy Data of Job Availablity
```{r indeed, echo=FALSE, message=FALSE, warning=FALSE}
source('~/Desktop/Data Wrangling/abbr2state.R') # function to conver the abb.state into full state names
# Data Scientist
job_title <- "\"Data+Scientist\""

ADV_URL <- NULL
job_count <- NULL
for (i in 1:50){
  location <- state.abb[i]
  ADV_URL <- paste0('https://www.indeed.com/jobs?as_and=&as_not=&as_cmp=&jt=all&st=&salary=&sr=directhire&radius=25&fromage=any&limit=50&sort=date&psf=advsrch&as_any=&as_phr=&as_ttl=', job_title, '&l=', location)
  start_page <- read_html(ADV_URL)
  count <- unlist(strsplit(start_page %>% 
                                 html_node("#searchCount") %>%
                                 html_text(), split = ' ')) 
  job_count[i] <- as.numeric(gsub(",", "", count[12]))
}

df_ds <- cbind(region = abbr2state(state.abb),job_count)
df_ds <- as.data.frame(df_ds)
df_ds$job_count <- as.numeric(as.character(df_ds$job_count))
df_ds$region <- tolower(df_ds$region)
df_ds <- df_ds %>% mutate(title= "Data Scientist")
ds_opt_states <- df_ds[which(df_ds$job_count>50),]

#Business Analyst
job_title <- "\"Business+Analyst\""

ADV_URL <- NULL
job_count <- NULL
for (i in 1:50){
  location <- state.abb[i]
  ADV_URL <- paste0('https://www.indeed.com/jobs?as_and=&as_not=&as_cmp=&jt=all&st=&salary=&sr=directhire&radius=25&fromage=any&limit=50&sort=date&psf=advsrch&as_any=&as_phr=&as_ttl=', job_title, '&l=', location)
  start_page <- read_html(ADV_URL)
  count <- unlist(strsplit(start_page %>% 
                             html_node("#searchCount") %>%
                             html_text(), split = ' ')) 
  job_count[i] <- as.numeric(gsub(",", "", count[12]))
}

df_ba <- cbind(region = abbr2state(state.abb),job_count)
df_ba <- as.data.frame(df_ba)
df_ba$job_count <- as.numeric(as.character(df_ba$job_count))
df_ba$region <- tolower(df_ba$region)
df_ba <- df_ba %>% mutate(title= "Business Analyst")
ba_opt_states <- df_ba[which(df_ba$job_count>50),]


#Data Analyst
job_title <- "\"Data+Analyst\""

ADV_URL <- NULL
job_count <- NULL
for (i in 1:50){
  location <- state.abb[i]
  ADV_URL <- paste0('https://www.indeed.com/jobs?as_and=&as_not=&as_cmp=&jt=all&st=&salary=&sr=directhire&radius=25&fromage=any&limit=50&sort=date&psf=advsrch&as_any=&as_phr=&as_ttl=', job_title, '&l=', location)
  start_page <- read_html(ADV_URL)
  count <- unlist(strsplit(start_page %>% 
                             html_node("#searchCount") %>%
                             html_text(), split = ' ')) 
  job_count[i] <- as.numeric(gsub(",", "", count[12]))
}

df_da <- cbind(region = abbr2state(state.abb),job_count)
df_da <- as.data.frame(df_da)
df_da$job_count <- as.numeric(as.character(df_da$job_count))
df_da$region <- tolower(df_da$region)
df_da <- df_da %>% mutate(title= "Data Analyst")
ba_opt_states <- df_da[which(df_da$job_count>50),]

# Data Engineer
job_title <- "\"Data+Engineer\""

ADV_URL <- NULL
job_count <- NULL
for (i in 1:50){
  location <- state.abb[i]
  ADV_URL <- paste0('https://www.indeed.com/jobs?as_and=&as_not=&as_cmp=&jt=all&st=&salary=&sr=directhire&radius=25&fromage=any&limit=50&sort=date&psf=advsrch&as_any=&as_phr=&as_ttl=', job_title, '&l=', location)
  start_page <- read_html(ADV_URL)
  count <- unlist(strsplit(start_page %>% 
                             html_node("#searchCount") %>%
                             html_text(), split = ' ')) 
  job_count[i] <- as.numeric(gsub(",", "", count[12]))
}

df_de <- cbind(region = abbr2state(state.abb),job_count)
df_de <- as.data.frame(df_de)
df_de$job_count <- as.numeric(as.character(df_de$job_count))
df_de$region <- tolower(df_de$region)
df_de <- df_de %>% mutate(title= "Data Engineer")
de_opt_states <- df_de[which(df_de$job_count>50),]

#Business Intelligence
job_title <- "\"Business+Intelligence\""

ADV_URL <- NULL
job_count <- NULL
for (i in 1:50){
  location <- state.abb[i]
  ADV_URL <- paste0('https://www.indeed.com/jobs?as_and=&as_not=&as_cmp=&jt=all&st=&salary=&sr=directhire&radius=25&fromage=any&limit=50&sort=date&psf=advsrch&as_any=&as_phr=&as_ttl=', job_title, '&l=', location)
  start_page <- read_html(ADV_URL)
  count <- unlist(strsplit(start_page %>% 
                             html_node("#searchCount") %>%
                             html_text(), split = ' ')) 
  job_count[i] <- as.numeric(gsub(",", "", count[12]))
}

df_bi <- cbind(region = abbr2state(state.abb),job_count)
df_bi <- as.data.frame(df_bi)
df_bi$job_count <- as.numeric(as.character(df_bi$job_count))
df_bi$region <- tolower(df_bi$region)
df_bi <- df_bi %>% mutate(title= "Business Intelligence")
bi_opt_states <- df_bi[which(df_bi$job_count>50),]

combi <- rbind(df_ba,df_bi,df_da,df_de,df_ds)
write.csv(combi, file = "job_availablity.csv")

datatable(combi, caption = 'Table: Tidy Data of Job Availablity')
```



```{r echo=FALSE}
## Plots
combi %>%
  right_join(map_data("state"),by = "region") %>%
  ggplot(aes(x=long,y=lat,group=group)) +
  geom_polygon(aes(fill=job_count)) +
  facet_wrap(~ title, ncol = 3) +
  scale_fill_gradient2(name = "Job Counts") +
  ggtitle("Figure: Job Counts by Job Titles") +
  expand_limits() +
  theme_void() +
  theme(strip.text.x = element_text(size = 12),
        text = element_text(family = "Georgia"),
        plot.title = element_text(size = 28, margin = margin(b = 10)),
        plot.subtitle = element_text(size = 12, color = "darkslategrey", margin = margin(b = 25)))
```



```{r echo=FALSE, warning=FALSE}
totalCount<- NULL
totalCount$region <- df_ba$region

for (i in 1:50){
  totalCount$job_count[i] <- sum(df_ba$job_count[i]+df_bi$job_count[i]+df_da$job_count[i]+df_de$job_count[i]+df_ds$job_count[i])
}

totalCount$region <- as.character(totalCount$region)
totalCount<-as.data.frame(totalCount)

totalCount %>%
  right_join(map_data("state"), by = "region") %>%
  select(-subregion) %>% 
  ggplot(aes(x=long,y=lat,group=group)) +
  geom_polygon(aes(fill=job_count)) +
  scale_fill_gradient2(name = "job_count") +
  ggtitle("Total Job Count")+
  expand_limits() +
  theme_void() +
  theme(strip.text.x = element_text(size = 12),
        text = element_text(family = "Georgia"),
        plot.title = element_text(size = 28, margin = margin(b = 10)),
        plot.subtitle = element_text(size = 12, color = "darkslategrey", margin = margin(b = 25)))
```



## Scrap data from USNews.com for 3 programs 

### Statistics 
```{r include=FALSE}

url <- NULL
page_num <- NULL
stat_res <- NULL

# 6 pages of results in total
# use for loop to get names and locations
for (i in 1:6){
  page_num <- i
  url <- paste0("https://www.usnews.com/best-graduate-schools/search?sort=rank_sort&sortdir=asc&program_rank=top_50&program=top-statistics-schools&page=", page_num)

  schoolname <- url %>% 
    read_html() %>% 
    html_nodes(".schoolname") %>% 
    html_text()
  
  citystate <- url %>% 
    read_html() %>% 
    html_nodes(".citystate") %>% 
    html_text()
  
  lists <- data.frame(
    name = schoolname,
    location = citystate
  )
  
  stat_res <- rbind(stat_res,lists)
}

stat_res <- stat_res[!duplicated(stat_res$name), ]
head(stat_res)
```

### Business
```{r include=FALSE}

url <- NULL
page_num <- NULL
busi_res <- NULL

# 6 pages of results in total
# use for loop to get names and locations
for (i in 1:6){
  page_num <- i
  url <- paste0("https://www.usnews.com/best-graduate-schools/search?program=top-business-schools&specialty=&name=&zip=&program_rank=top_50&enrollment-min=0&enrollment-max=1000&tuition_and_fees-min=5000&tuition_and_fees-max=50000&sort=program_rank&sortdir=asc&page=", page_num)
  
  schoolname <- url %>% 
    read_html() %>% 
    html_nodes(".schoolname") %>% 
    html_text()
  
  citystate <- url %>% 
    read_html() %>% 
    html_nodes(".citystate") %>% 
    html_text()
  
  lists <- data.frame(
    name = schoolname,
    location = citystate
  )
  
  busi_res <- rbind(busi_res,lists)
}

busi_res <- busi_res[!duplicated(busi_res$name), ]
head(busi_res)
```


### Computer Science
```{r include=FALSE}

url <- NULL
page_num <- NULL
cs_res <- NULL

# 6 pages of results in total
# use for loop to get names and locations
for (i in 1:6){
  page_num <- i
  url <- paste0("https://www.usnews.com/best-graduate-schools/search?program=top-computer-science-schools&specialty=&name=&zip=&program_rank=top_50&sort=program_rank&sortdir=asc&page=", page_num)
  
  schoolname <- url %>% 
    read_html() %>% 
    html_nodes(".schoolname") %>% 
    html_text()
  
  citystate <- url %>% 
    read_html() %>% 
    html_nodes(".citystate") %>% 
    html_text()
  
  lists <- data.frame(
    name = schoolname,
    location = citystate
  )
  
  cs_res <- rbind(cs_res,lists)
}

cs_res <- cs_res[!duplicated(cs_res$name), ]
head(cs_res)
```


```{r,include=FALSE}

## create tidy data
############## clean the names #############################
busi_res$location<- as.character(busi_res$location)
stat_res$location<- as.character(stat_res$location)
cs_res$location<- as.character(cs_res$location)

busi_res$name<- as.character(busi_res$name)
stat_res$name<- as.character(stat_res$name)
cs_res$name<- as.character(cs_res$name)

########################################################
# we don't need the specific school names
# delect them and merge three data set to get distinct university names
############### business ############################

n <- length(busi_res$name)

for (i in 1:n){
  if (str_detect(busi_res$name[i],"\\(")){
    busi_res$name[i] <- sub("(.*?)\\(.*", "\\1", busi_res$name[i])
  }
  else{
    busi_res$name[i] <- sub("(.*?)\\s\\-.*", "\\1", busi_res$name[i])
  }
}


############### CS ############################
n <- length(cs_res$name)

for (i in 1:n){
  if (str_detect(cs_res$name[i],"\\(")){
    cs_res$name[i] <- sub("(.*?)\\(.*", "\\1", cs_res$name[i])
  }
  else{
    cs_res$name[i] <- sub("(.*?)\\s\\-.*", "\\1", cs_res$name[i])
  }
}

######### create new variables(region, city) ############################

n <- length(stat_res$name)
for (i in 1:n){
  if (str_detect(stat_res$name[i],"\\(")){
    stat_res$name[i] <- sub("(.*?)\\(.*", "\\1", stat_res$name[i])
  }
  else{
    stat_res$name[i] <- sub("(.*?)\\s\\-.*", "\\1", stat_res$name[i])
  }
}

```


## Glimpse of tidy data after cleaning the names
```{r echo=FALSE}
tot <- rbind(cs_res,stat_res,busi_res)
tot <- tot[!duplicated(tot$name), ]
write.csv(tot, file = "graduate_sch.csv")
```


```{r message=FALSE, warning=FALSE, include=FALSE}

tot <- rbind(cs_res,stat_res,busi_res)
tot <- tot[!duplicated(tot$name), ]
write.csv(tot, file = "graduate_sch.csv")

df <- NULL
for (i in 1:nrow(tot)){
  df$school[i] <- tot$name[i]
  code <- geocode(as.character(tot$name[i]))
  df$lng[i] <- code[1]
  df$lat[i] <- code[2]
}
```


## Visualize the Distribution of Universities
```{r echo=FALSE, message=FALSE, warning=FALSE}
df <- NULL
for (i in 1:nrow(tot)){
  df$school[i] <- tot$name[i]
  code <- geocode(as.character(tot$name[i]))
  df$lng[i] <- code[1]
  df$lat[i] <- code[2]
}

df$lng <- unlist(df$lng)
df$lat <- unlist(df$lat)

leaflet() %>% addTiles()  %>% setView(-97, 40, zoom = 4) %>%
  addMarkers(data = df,lng= ~ lng,lat=~lat,popup= df$school)
```
In general, the most expensive areas to live were Hawaii, Alaska, the West Coast, and the Northeast. The least expensive areas were the Midwest and Southern states.


```{r echo=FALSE}
cost_liv <- read.csv("cost_of_living.csv",header = TRUE)

colnames(cost_liv)[1] <- "region"
cost_liv$region <- tolower(as.character(cost_liv$region))
cost_liv <- cost_liv %>% select(region, Index)
```


## Visualize Cost of Living (2017 Annual Average)
```{r echo=FALSE}
cost_liv %>%
  right_join(map_data("state"), by = "region") %>%
  select(-subregion) %>% 
  ggplot(aes(x=long,y=lat,group=group)) +
  geom_polygon(aes(fill=Index)) +
  scale_fill_gradient2(name = "Index") +
  expand_limits() +
  theme_void() +
  theme(strip.text.x = element_text(size = 12),
        text = element_text(family = "Georgia"),
        plot.title = element_text(size = 28, margin = margin(b = 10)),
        plot.subtitle = element_text(size = 12, color = "darkslategrey", margin = margin(b = 25)))
```